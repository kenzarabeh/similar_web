# ğŸš€ Quick Start - SimilarWeb Data Pipeline

## â±ï¸ DÃ©marrage en 5 minutes

### 1ï¸âƒ£ Installation express
```bash
# Cloner/Extraire le projet
cd similarweb_for_data_scientist_*

# Environnement virtuel
python3 -m venv venv
source venv/bin/activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configuration
cp config/env.example config/.env
# â†’ Ã‰diter config/.env et ajouter votre clÃ© API
```

### 2ï¸âƒ£ Premier test
```bash
# Extraire les donnÃ©es du mois dernier
python scripts/daily_extraction.py --test_mode

# Si succÃ¨s, extraire un mois complet
python scripts/daily_extraction.py --year 2025 --month 11
```

### 3ï¸âƒ£ VÃ©rifier les rÃ©sultats
```bash
# Les donnÃ©es sont dans data/
ls data/segments/
ls data/websites/
```

## ğŸ“ Structure du projet

```
ğŸ“¦ similarweb_for_data_scientist/
â”œâ”€â”€ ğŸ“œ README.md                    # Guide complet
â”œâ”€â”€ ğŸš€ QUICKSTART_DATA_SCIENTIST.md # Ce fichier
â”œâ”€â”€ â˜ï¸  DEPLOYMENT_GUIDE_GCP.md     # Guide dÃ©ploiement cloud
â”œâ”€â”€ ğŸ” BIGQUERY_QUERIES_EXAMPLES.md # RequÃªtes SQL utiles
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                     # Scripts Python
â”‚   â”œâ”€â”€ similarweb_api.py          # API wrapper principal
â”‚   â”œâ”€â”€ daily_extraction.py        # Extraction quotidienne
â”‚   â”œâ”€â”€ historical_backfill.py     # RÃ©cupÃ©ration historique
â”‚   â””â”€â”€ upload_to_bigquery.py      # Upload vers BigQuery
â”‚
â”œâ”€â”€ ğŸ“‚ gcp_deployment/             # Tout pour GCP
â”‚   â”œâ”€â”€ cloud_functions/          # Code des fonctions
â”‚   â”œâ”€â”€ scripts/                  # Scripts de dÃ©ploiement
â”‚   â””â”€â”€ terraform/                # Infrastructure as Code
â”‚
â”œâ”€â”€ ğŸ“‚ config/                     # Configuration
â”‚   â”œâ”€â”€ env.example              # Template variables
â”‚   â””â”€â”€ config.py                # Config Python
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                       # Documentation
â”‚   â”œâ”€â”€ API_DOCUMENTATION.md     # DÃ©tails techniques
â”‚   â””â”€â”€ AUTOMATISATION_GCP.md    # Guide automatisation
â”‚
â””â”€â”€ ğŸ“‚ notebooks/                  # Jupyter notebooks
    â””â”€â”€ SimilarWeb_Exploration.ipynb
```

## ğŸ¯ Cas d'usage principaux

### ğŸ“Š Extraction manuelle
```bash
# Mois spÃ©cifique
python scripts/daily_extraction.py --year 2025 --month 10

# Historique complet (12 mois)
python scripts/historical_backfill.py

# Segments uniquement
python scripts/extract_user_segments_only.py
```

### â˜ï¸ Upload BigQuery (si GCP configurÃ©)
```bash
# Upload des fichiers JSON locaux
python scripts/upload_to_bigquery.py
```

### ğŸ”„ Automatisation GCP
Voir `DEPLOYMENT_GUIDE_GCP.md` pour le guide complet

## ğŸ’¡ Tips essentiels

### ğŸ”‘ ClÃ© API
- Demandez votre clÃ© Ã  l'Ã©quipe
- Testez avec `--test_mode` d'abord
- Quota typique : 10k appels/mois

### ğŸ“… DÃ©lai des donnÃ©es
- SimilarWeb a un dÃ©lai de 7 jours
- DonnÃ©es de novembre disponibles aprÃ¨s le 7 dÃ©cembre

### ğŸ¯ Segments disponibles
- 88 segments personnalisÃ©s (avec `userOnlySegments=true`)
- OrganisÃ©s par secteur : Parapharmacie, High-Tech, etc.

### ğŸ“ˆ MÃ©triques extraites
- **Visits** : Nombre de visites
- **Share** : Part de marchÃ©
- **Bounce Rate** : Taux de rebond
- **Pages/Visit** : Pages par visite
- **Duration** : DurÃ©e moyenne (secondes)

## ğŸ†˜ ProblÃ¨mes frÃ©quents

| ProblÃ¨me | Solution |
|----------|----------|
| "API Key invalid" | VÃ©rifier la clÃ© dans `config/.env` |
| "Rate limit" | Le script gÃ¨re automatiquement, patienter |
| DonnÃ©es manquantes | VÃ©rifier le dÃ©lai de 7 jours |
| Erreur Python | VÃ©rifier Python 3.11+ et dÃ©pendances |

## ğŸ“ Support

1. **Documentation** : Voir le dossier `docs/`
2. **Exemples SQL** : Voir `BIGQUERY_QUERIES_EXAMPLES.md`
3. **Notebook** : Explorer avec Jupyter

## âœ… Checklist de dÃ©marrage

- [ ] ClÃ© API configurÃ©e dans `.env`
- [ ] Test avec `--test_mode` rÃ©ussi
- [ ] PremiÃ¨re extraction complÃ¨te
- [ ] DonnÃ©es visibles dans `data/`
- [ ] (Optionnel) GCP configurÃ©
- [ ] (Optionnel) BigQuery opÃ©rationnel

Bonne analyse ! ğŸ‰ 