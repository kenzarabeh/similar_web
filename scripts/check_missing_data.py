#!/usr/bin/env python3
"""
Script pour v√©rifier toutes les donn√©es manquantes depuis janvier 2024
"""
from datetime import datetime, date, timedelta
from google.cloud import bigquery

def check_missing_data():
    """V√©rifie quelles donn√©es sont manquantes pour 2024 et 2025"""
    
    # Dates de d√©but et fin
    start_date = date(2024, 1, 1)
    end_date = datetime.now().date() - timedelta(days=3)  # J-3 (d√©lai SimilarWeb)
    
    # Initialiser BigQuery
    client = bigquery.Client(project='similarweb-intel-dev')
    
    # R√©cup√©rer les dates existantes
    query = """
    SELECT DISTINCT DATE(date) as existing_date
    FROM `similarweb-intel-dev.similarweb_data.segments_data`
    ORDER BY existing_date
    """
    
    existing_dates = set()
    for row in client.query(query).result():
        existing_dates.add(row.existing_date)
    
    print("üìä ANALYSE DES DONN√âES MANQUANTES")
    print("=" * 60)
    print(f"P√©riode analys√©e: {start_date} √† {end_date}")
    print(f"Donn√©es existantes: {len(existing_dates)} jours")
    print(f"Jours dans BigQuery: {sorted(existing_dates)}")
    
    # Calculer les donn√©es manquantes par mois
    current = start_date
    missing_by_month = {}
    total_missing = 0
    
    while current <= end_date:
        month_key = current.strftime('%Y-%m')
        if month_key not in missing_by_month:
            missing_by_month[month_key] = []
        
        if current not in existing_dates:
            missing_by_month[month_key].append(current)
            total_missing += 1
        
        current += timedelta(days=1)
    
    print(f"\n‚ùå DONN√âES MANQUANTES: {total_missing} jours")
    print("-" * 60)
    
    # Afficher par mois
    for month, days in missing_by_month.items():
        if days:
            print(f"\nüìÖ {month}: {len(days)} jours manquants")
            if len(days) <= 5:  # Afficher les dates si peu nombreuses
                for day in days:
                    print(f"   - {day}")
            else:
                print(f"   - Du {days[0]} au {days[-1]}")
    
    # Estimation du temps et co√ªt
    print(f"\nüí∞ ESTIMATION POUR R√âCUP√âRER TOUTES LES DONN√âES")
    print("-" * 60)
    
    # Pour l'extraction quotidienne, on utilise la granularit√© 'daily'
    # Ce qui n√©cessite de faire des appels mois par mois
    months_to_extract = len(missing_by_month)
    api_calls = months_to_extract * 88 * 3  # 88 segments √ó 3 m√©triques
    time_estimate = (api_calls * 1.5) / 60  # 1.5 secondes par appel
    
    print(f"üìÖ Mois √† extraire: {months_to_extract}")
    print(f"üìû Appels API estim√©s: {api_calls:,}")
    print(f"‚è±Ô∏è  Temps estim√©: {time_estimate:.1f} heures")
    print(f"üíµ Co√ªt estim√©: ~${api_calls * 0.001:.2f} (√† $0.001/appel)")
    
    # Strat√©gie recommand√©e
    print(f"\nüéØ STRAT√âGIE RECOMMAND√âE")
    print("-" * 60)
    print("1. BACKFILL HISTORIQUE (une fois)")
    print("   - Extraire toutes les donn√©es 2024 (par mois)")
    print("   - Extraire donn√©es 2025 jusqu'√† aujourd'hui")
    print("   - Dur√©e: ~1-2 jours en plusieurs batches")
    print("\n2. EXTRACTION QUOTIDIENNE (automatique)")
    print("   - Cloud Function qui v√©rifie J-2 √† J-7")
    print("   - R√©cup√®re automatiquement les donn√©es manquantes")
    print("   - Co√ªt: ~$0.50/jour")
    
    return {
        'total_days_expected': (end_date - start_date).days + 1,
        'days_existing': len(existing_dates),
        'days_missing': total_missing,
        'missing_by_month': missing_by_month
    }

if __name__ == "__main__":
    result = check_missing_data() 